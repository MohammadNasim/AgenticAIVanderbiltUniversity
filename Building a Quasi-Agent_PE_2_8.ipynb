{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadNasim/AgenticAIVanderbiltUniversity/blob/main/Building%20a%20Quasi-Agent_PE_2_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "      # Step 2: Code from previous LLM output\n",
        "      generated_code = \"\"\"\n",
        "      def factorial(n):\n",
        "          if n == 0 or n == 1:\n",
        "              return 1\n",
        "          else:\n",
        "              return n * factorial(n-1)\n",
        "      \"\"\".strip()  # Replace this with code from the earlier step\n",
        "\n",
        "      # Step 3: Prompt LLM to add documentation\n",
        "      prompt = f\"\"\"Add comprehensive documentation to the following Python function. Include:\n",
        "      - Function description\n",
        "      - Parameter descriptions\n",
        "      - Return value description\n",
        "      - Example usage\n",
        "      - Edge cases\n",
        "\n",
        "      Here is the function:\n",
        "\n",
        "      ```python\n",
        "      {generated_code}\n",
        "      ```\"\"\"\n",
        "\n",
        "      # Step 4: Call LLM\n",
        "\n",
        "      messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "\n",
        "# Step 5: Display documented response\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ]
    }
  ]
}